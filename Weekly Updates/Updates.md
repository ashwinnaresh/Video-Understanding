


# Video Understanding - Weekly Updates

This document contains the weekly updates on the video understanding project for the MIIS Capstone requirement.

## Work done since the final presentation in May

An initial topic analysis of the videos in the How-To dataset was done using the video transcriptions. The dominant topics of the videos were Health, Yoga, Cooking, Stitching to name a few. 

## 09/05 - 09/12

Member | Upcoming Tasks 
------ | ---------------
Arvind | Get similar dissimilar videos clustered:<ul><li>Analyze topic distribution</li><li>Get similar videos based on empirical threshold</li><li>Reduce the empirical threshold to get dissimilar videos</li></ul>
Ashwin | Get summarization baselines up and running:<ul><li>Setup environment</li><li>OpenNMT baseline for summarizing videos based on transcription</li><li>Stretch goal: Experiment with action features along with text for summarization</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><li>Literature survey</li><li>Implementation of simple techniques like n-gram overlap, LCS</li><li>Stretch goal : DTW</li></ul>

## 09/12 - 09/19

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | Get similar dissimilar videos clustered:<ul><li>Analyze topic distribution - Checked a 50 topic LDA distribution. The topics seem to be well formed but the choice of the number of latent topics is yet to be confirmed.</li><li>Get similar videos based on empirical threshold - Identified yoga as one of the "hot topics". Evaluated DBSCAN, HDBSCAN, K-means and KNN based on intrinsic measures.</li><li>Reduce the empirical threshold to get dissimilar videos - Basic tests based on KNNs. Threshold setting still an open question</li></ul> | <ul><li>Setup extrinsic evaluation of LDA topics</li><li>Setup extrinsic evaluation of the similar and dissimilar clusters</li><li>Tune the clustering, choice of k in kNN and number of topics based ib the extrinsic evaluation</li></ul>
Ashwin | Get summarization baselines up and running:<ul><li>Setup environment - Environment setup on Rocks cluster</li><li>OpenNMT baseline for summarizing a video based on transcription - Model has been trained. It needs to be evaluated with ROUGE.</li><li>Stretch goal: Experiment with action features along with text for summarization - Not started</li></ul> | <ul><li>Evaluate the trained model on ROUGE and content F1 score metrics</li><li>Experiment with action features along with text for summarization</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><li>Literature survey - Surveyed multiple methods for aligning text in documents</li><li>Implementation of simple techniques like n-gram overlap, LCS - Used other techniques like Rogue and Edit Distance from Survey</li><li>Stretch goal : DTW - Might not be relevant for our use case</li></ul> | <ul><li>Currently experimenting with multiple similiarity scores</li><li>Will have to evaluated the techniques on multiple pairs of videos from different domains to choose the most robust method on identifiying differences</li></ul>

## 09/19 - 09/26

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Setup extrinsic evaluation of LDA topics - Primary evaluation based on the kNN for videos (subjective)</li><li>Setup extrinsic evaluation of the similar and dissimilar clusters - Subjective evaluation completed. Extrinsic evaluation will be possible after a few downstream tasks are defined</li><li>Tune the clustering, choice of k in kNN and number of topics based on the extrinsic evaluation - Implemented a re-ranking metric for kNN based on content similarity in the retrieved neighbours</li></ul> | <ul><li>Try content F1 score and other content similarity measures (METEOR/ ROUGE) to get better distinction between similar and dissimilar videos</li><li>Identify main sets of topics to focus on for initial evaluation</li><li>Improve the interpretibility of the different techniques by juxtaposing the results appropriately.</li><li>Stretch goals: <ul><li>Design model for difference generation</li></li></ul>
Ashwin | <li>Evaluate the trained model on ROUGE and content F1 score metrics - Model evaluated on BLEU-4 (30.797), ROUGE-L (50.3) and METEOR (25.21) scores</li><li>Summarization model trained with video action features and text which gave scores of BLEU-4 (37.197), ROUGE-L (55.6) and METEOR (28.71) </li></ul> | <ul><li>Figure out how to compute content F1 score and evaluate model on it</li><li>Visualize the attention of the summarization model</li><li>Design model architecture for difference generation</li><li>Stretch goals: <ul><li>Implement model and train for difference generation (on dummy data atleast)</li><li>Experiment with object and scene features for summarization</li></ul></li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><li> Implemented a time alignment methodology to align transcriptions with respect to a similarity score</li><li>Evaluated techniques on multiple similarity scores</li></ul> | <ul><li>Implement the Viterbi algortihm to align sentences and use a similairy metric in between to decide insertions and deletions</li><li>Create a grah based to structure to better visualize the sentences which are similar for the videos</li></ul>

## 09/26 - 10/03

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Try content F1 score and other content similarity measures (METEOR/ ROUGE) to get better distinction between similar and dissimilar videos - Content F1 score is not in any literature. New metric defined, which is a modification of METEOR. Need more understanding before using it</li><li>Identify main sets of topics to focus on for initial evaluation - Relationships, Yoga, Excercise were the major topics</li><li>Improve the interpretibility of the different techniques by juxtaposing the results appropriately. - Made a simple UI for comparing different ranking mechanisms</li><li>Stretch goals: <ul><li>Design model for difference generation - Siamese network with a probable heirarchical attention mechanism. Evaluating NMTPytorch for building the seq2seq model.</li></li></ul> | <ul><li>Implement the initial model in NMTPy</li><li>Train the above model on Yoga videos</li><li>Stretch goals: <ul><li>Try MMR based dissimilar sentence retrieval.<li>Perform error analysis on the summaries generated</li></li></li></ul>
Ashwin | <ul><li>Implement model and train for difference generation (on dummy data atleast) - Model has been implemented; it is a siamese seq2seq model with 3-way tied encoders and 2 decoders. The end to end network optimizes the cross entropy loss and there is an auxiliary triplet loss at the encoder.  Gradients explode for some of the training batches randomly leading to NaN loss values; Working on fixing this issue</li><li>Experiment with object and scene features for summarization - Script to extract the object and place features (imagenet and places CNN) is ready and tested on a small sample. There is a storage constraint on the cluster to save these features. This experiment is on hold until the storage logistics are figured out.</li><li>Stretch goal - Manually evaluated some initial data triplets based on the topic similarity</li></ul> | <ul><li>Fix the NaN loss issue</li><li>Train and evaluate model on the sample triplet data extracted so far</li><li>Stretch goal - Experiment with 2 encoders and 1 decoder by randomizing the target as summary of either of the videos and see if network is learning anything</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><ul><li>Implemented the Viterbi algortihm to align sentences and use a similairy metric in between to decide insertions and deletions</li><li>Currently evaluating the approach and researching on other ways to carry out this task</li></ul> | <ul><li>Create a graph based to structure to better visualize the sentences which are similar for the videos</li></ul>

## 10/03 - 10/10

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Implement the initial model in NMTPy - Simplistic model is ready.</li><li>Train the above model on Yoga videos - Created the necessary triplets for training</li><li>Stretch goals: <ul><li>Try MMR based dissimilar sentence retrieval. - results not promising<li>Perform error analysis on the summaries generated - not started</li></li></li></ul> | <ul><li>Add attention to the summary generation</li><li>Evaluate the summaries generated manually</li>
Ashwin | <ul><li>Implement model and train for difference generation (on dummy data atleast) - Model has been implemented; it is a siamese seq2seq model with 3-way tied encoders and 2 decoders. The end to end network optimizes the cross entropy loss and there is an auxiliary triplet loss at the encoder.  Gradients explode for some of the training batches randomly leading to NaN loss values; Working on fixing this issue</li><li>Experiment with object and scene features for summarization - Script to extract the object and place features (imagenet and places CNN) is ready and tested on a small sample. There is a storage constraint on the cluster to save these features. This experiment is on hold until the storage logistics are figured out.</li><li>Stretch goal - Manually evaluated some initial data triplets based on the topic similarity</li></ul> | <ul><li>Fix the NaN loss issue</li><li>Train and evaluate model on the sample triplet data extracted so far</li><li>Stretch goal - Experiment with 2 encoders and 1 decoder by randomizing the target as summary of either of the videos and see if network is learning anything</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><ul><li>Researched on multiple methods to get the right alignment. Taking a different approavh towards the problem</li><li>Going through the dataset to choose pairs of similar videos where the differences are clear</li></ul> | <ul><li>Implement and evaluate the multiple methods researched in the previous week</li><li>Finalize of aligning method and run for rest of the corpus</li></ul>
  
## 10/10 - 10/17

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Add attention to the summary generation - Implemented 2 encoder 1 decoder model with hierarchical attention</li><li>Evaluate the summaries generated manually - proved challenging as the trained model overfit on the data as number of samples were just 1000</li> | <ul><li>Presentation preparation</li><li>Experiment with the entire dataset. <ul><li>Hierarchical attention with similar videos</li><li>Hierarchical attention with dissimilar videos</li><li>Reduce the constraints on triplet creation by sampling from a range of nearest neighbours</li></ul></li><li>Strecth goals: <ul><li>3 encoder 2 decoder model with hierarchical attention implementation</li></ul></li></ul>
Ashwin | <ul><li>Fix the NaN loss issue - loss issue fixed</li><li>Train and evaluate model on the sample triplet data extracted so far - Model seems to be overfitting on the sample data. This conclusion was drawn after manually going through a random sample of model output - Evaluation metrics on held out set: BLEU (27.312), METEOR (24.473) and ROUGE-L (47.1)</li><li>Stretch goal - Experiment with 2 encoders and 1 decoder by randomizing the target as summary of either of the videos and see if network is learning anything - Model seems to be overfitting as it is being trained on just 1K pairs. Evaluation metrics on held out set: BLEU (28.221), METEOR (22.707) and ROUGE-L (46.3)</li></ul> | <ul><li>Experiment with the 2 encoder 1 decoder setup by training on pairs created from the full dataset and see if the summaries generated are comparable to the summarization baselines</li><li>Prepare the slide deck for the mid presentation</li><li>Stretch goal - Experiment using 2 different encoders and weight tied encoders, hierarchical attention and concatenated attention between the 2 encoders</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><ul><li>Finalized on using Rogue as a metric to align the videos</li><li>Created scripts to find differences in videos</li></ul> | <ul><li>Revisit the triplet sampling technique</li><li>Help my teammates with bringing up the baseline</li></ul>

## 10/24 - 10/31

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Presentation preparation - completed mid sem presentation</li><li>Experiment with the entire dataset. - ROUGE scores were not satisfactory. Found a major bug in the hierarchical attention implementation<ul><li>Hierarchical attention with similar videos</li><li>Hierarchical attention with dissimilar videos</li><li>Reduce the constraints on triplet creation by sampling from a range of nearest neighbours</li></ul></li><li>Strecth goals: <ul><li>3 encoder 2 decoder model with hierarchical attention implementation - Finding the bug didn't leave time for this</li></ul></li></ul> | <ul><li>Look at the problem as a sequence tagging problem</li><li>Build a multi-task multi-encoder single decoder network</li><li>Rerun experiments with the new network after the bug fix</li></ul>
Ashwin | <ul><li>Presentation preparation - completed mid sem presentation</li><li>Experiment with the 2 encoder 1 decoder setup by training on pairs created from the full dataset and see if the summaries generated are comparable to the summarization baselines - The 2 encoder 1 decoder setup achieved a ROUGE of 31 whereas the single video summarization baseline achieves a ROUGE of 50.3 <li> Experiment using 2 different encoders and weight tied encoders, hierarchical attention and concatenated attention between the 2 encoders - <ul><li>2 different encoders + 1 decoder - This setup was used for generating differences and the model did not seem to be learning anything</li><li>2 shared encoders + 1 decoder - This setup was used for both generating summaries and differences - It gave a ROUGE of 31 for summaries and 20.8 for differences</li><li>All experiments above were run with hierarchical attention as the model was not learning anything with concatenated attention</li><li>Similar set of experiments were also run for within topic, 2 video summarization and difference generation using the 2 encoder 1 decoder setup - summary generation within topic achieved a ROUGE score of 45.57 whereas on similarity generation (inverse logic for creating differences), model gave a ROUGE of 59.86</li></ul></li><li>Inference from the experiments above - <ul><li>Better sampling of nearest neighbors for input pairs required - directly use Jaccard similarity/ROUGE</li></ul></li></ul> | <ul><li>Look at the problem as sequence tagging problem where each token is tagged as similar/different</li><li>Literature survey on gradient reversal training for multi task learning</li><li>Refine the architecture for the multi-task learning</li><li>Rerun experiments with the new input pairs (based only on jacquard and not topic vectors)</li></ul>
Madhura | Training Dataset Creation and Experiments<ul><ul><li>Created multiple variations for training dataset</li><li>Devised a sampling strategy for choosing similar videos using Rogue, Jaccard and KNN </li><li>Training and implementing variations of the baseline to get differences and similarities between videos</li>  </ul> | <ul><li>Working on changing the problem from a generation problem to a tagging problem</li><li>Run experiments all the various datasets using the tagging methodology</li></ul>

## 10/31 - 11/07

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Look at the problem as a sequence tagging problem - output of the model will now be a multitask output where one of the outputs is the auto-encoded word while the other is the similar/ difference tag</li><li>Build a multi-task multi-encoder single decoder network - Network built</li><li>Rerun experiments with the new network after the bug fix - Awaiting results</li></ul> | <ul><li>Modify NMTPyTorch framework to handle multitask learning system</li><li>Add evaluation for multitask output in the framework</li><li>Run experiments for the implemented multitask system</li></ul>
Ashwin | <ul><li>Look at the problem as sequence tagging problem where each token is tagged as similar/different - Ongoing (data ready, model and evaluation pipeline is being built)</li><li>Literature survey on gradient reversal training for multi task learning - Went through paper on adversarial multitask training which shows that gradient reversal at the task independent layers improves the learning </li><li>Rerun experiments with the new input pairs (based only on jaccard and not topic vectors) - Model is still being trained</li><li>Rerun experiments after fixing decoder bug - Test set ROUGE increases by 1 point.</li></ul> | <ul><li>Multi task learning evaluation pipeline setup</li><li>Evaluate the model on the new input pairs (based on Jaccard)</li></ul>
Madhura | Training Dataset Creation and Experiments<ul><ul><li>Created the dataset to work for the tagging problem.</li><li> Explored the framework to start working on an evaluation pipeline for our multi-task learning implementation</li><li>Training and implementing variations of the baseline to get differences and similarities between videos with the new implementation without the decoder bug</li>  </ul> | <ul><li>We want to achieve some preliminary results regarding the new problem setting</li><li>Experiments needs to be ran on multiple sampling settings as mentioned before</li></ul>
  
## 11/07 - 11/14

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Modify NMTPyTorch framework to handle multitask learning system - work in progress. NMTPyTorch isn't as flexible to changes as we had hoped.</li><li>Add evaluation for multitask output in the framework - Seeing if this can be done outside the framework</li><li>Run experiments for the implemented multitask system - Toy experiments have been run. Have to run for the full data</li></ul> | <ul><li>Complete the pending tasks from last week</li><li>Try generating and tagging 1 similar and 1 dissimilar sentence as opposed to a description and compare with the baseline</li><li>Think of a good presentation technique for manual analysis</li></ul>
Ashwin | <ul><li>Evaluate the model on the new input pairs (based on Jaccard) - Model performed worse (ROUGE dropped to 20.4) in generating the summaries as the neighbors sampled using only Jaccard are noisier than our initial neighbors based on topic vectors</li><li>Multi task learning evaluation pipeline setup - Discovered some inconsistencies during initial runs, working on resolving the bugs</li></ul> | <ul><li>Use the video titles to generate similarities and differences and train the model on this</li><li>Manually analyse reasonable similarity/differences between videos in the cooking topic</li></ul>
Madhura | Training Dataset Creation and Experiments<ul><ul><li>Evaluated the similarity generation with fixed decoder architecture</li><li>Created a tagged data for a tagging problem</li>  </ul> | <ul><li>Work on an evaluation of the ground truth generation</li><li>Create data which only gives out the most similar and dissimilar data</li></ul>
  
## 11/14 - 11/21

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Complete the pending tasks from last week - Completed the multitask flow</li><li>Try generating and tagging 1 similar and 1 dissimilar sentence as opposed to a description and compare with the baseline - Model difference generation on the full data improved to a ROUGE of 40.1 and 30.2 for the cooking topic. Similarities ROUGE is still at 20.</li><li>Think of a good presentation technique for manual analysis - Present possible noun phrases and ascertain their contribution to the difference</li></ul> | <ul><li>Manual analysis of the data shows unexpected behavior. Analyse and fix this</li><li>Look at generating differences after removing noun phrases which bias the model</li><li>Focus on noun phrase based difference generation by incorporating topic specific priors</li></ul>
Ashwin | <ul><li>Use the video titles to generate similarities and differences and train the model on this - instead of titles, differences and similarities were reduced to a length of 22 words - Model difference generation got an improved ROUGE of 40.1 on all topics and 30.2 on cooking topic. Similarities ROUGE is still at 20.</li><li>Manually analyse reasonable similarity/differences between videos - Differences picked up are generally the first sentences which mention the artist in the video</li></ul> | <ul><li>Presence of lot of UNKs in the generated differences - need to check input tokenization</li><li>Look at the problem in terms of generating differences and similarities based on the constituent NP - for the cooking topic, compute the ingredients coverage in all of the transcripts</li></ul>
Madhura | Training Dataset Creation and Experiments<ul><ul><li>Created the data and ran experiments to generate differences and similarities by reducing the target length and reordering of the sentences according to transcript order. Achieved a rogue score of 40 for differences and 30 for similarities.</li><li>The data had a lot of UNKs which may be a tokenization issue. Also, as most differences were chosen as sentence 1, have to remove the first sentence and recreate the data</li>  </ul> | <ul><li>Work on an evaluation of the ground truth generation</li><li>Run experiments on new setup of data</li></ul>

  
## 11/21 - 11/28

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Manual analysis of the data shows unexpected behavior. Analyse and fix this - text pre-processing correction fixed the issue</li><li>Look at generating differences after removing noun phrases which bias the model - Found method to be noisy</li><li>Focus on noun phrase based difference generation by incorporating topic specific priors - Didn't go ahead with this as the previous experiment was unsuccessful</li></ul> | <ul><li>Alignment fine tuning to improve overall performance</li><li>Literature survey to find any other models which have emerged in the area of difference generation</li><li>Global alignment strategy evaluation with a DP solution</li></ul>
Ashwin | <ul><li>Fixing input tokenization improved ROUGE scores</li><li>Difference ROUGE improved to 75 for all topics and similarities improved to 35</li><li>For the cooking topic, compute the ingredients coverage in all of the transcripts - 100% coverage based on extracted ingredients; 15.6 ingredients on average per transcript in train</li><li>Ingredients based differences and similarities seemed to be noisy</li></ul> | <ul><li>Result analysis shows that most differences picked up as the second sentence of the anchor transcript</li><li>Globally align the video pairs and then extract similarities or differences</li><li>Rerun similarities and differences experiment based on the new global alignment</li></ul>
Madhura | Training Dataset Creation and Experiments<ul><ul><li>New setup of tokenized has improved performance giving high ROUGE values of 60. The model has learnt to copy the first few sentences from the transcripts</li><li>To avoid the following, we have to generate the ground truth through heuristics using a max path sum algorithm</li>  </ul> | <ul><li>Generate new type of data and run experiments on it</li><li>Analyse the results and identify steps to wrap up the project</li></ul>

  
## 11/28 - 12/05

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Alignment fine tuning to improve overall performance - Using a DTW inspired ROUGE based sentence alignment. Looking at alternatives</li><li>Literature survey to find any other models which have emerged in the area of difference generation - None found in the domain of text generation</li><li>Global alignment strategy evaluation with a DP solution - Implemented a DP solution for the alignment and tested the model performance. Significant improvement in the extrinsic evaluation</li></ul> | <ul><li>Experiment with word vector based similarity metric</li><li>Perform some intrinsic evaluations for the alignments to analyze the behaviour</li><li>Start drafting the presentation</li><li>Stretch goal: Try out a multi-decoder architecture to learn similarities and differences simultaneously</li></ul>
Ashwin | <ul><li>Global alignment of transcripts based on ROUGE scores using DTW inspired alignment and then use the hard alignment to pick similarities and differences</li><li>This technique of extracting similarities and differences is globally optimal and has lesser overlap between sentences picked as similarities and differences</li><li>Model learns similarities and differences with comparable test ROUGEs to that of single video summarization baseline (~50)</li><li>Manually evaluated quality of similarities and differences</li></ul> | <ul><li>Result analysis shows that most differences are picked up from the initial few sentences of the anchor transcript and there is higher variance in the sentences being picked</li><li>Rerun experiments with word vector based alignment strategy</li><li>Start final presentation draft</li><li>Stretch : Shared decoder with multiple softmax layers to learn both similarities and differences</li></ul>
Madhura | <ul><ul><li>Max path sum to pick the most similar sentences were extracted and the lowest scores are treated as differences and highest as similarities</li><li>ROUGE scores of 50 were achieved for differences and 60 for similairities. Analysis on the data makes the extracted differences quite reasonable</li><li>The data is still skewed to sentences in the beginning</li>  </ul> | <ul><li>To overcome the skewed data, we need to remove the pair from the path itself</li><li>Create the similarity scores with respect to sentence embedding similarities rather than ROUGE scores</li></ul>
  
## 12/05 - 12/12

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Alignment fine tuning to improve overall performance - Using a DTW inspired ROUGE based sentence alignment. Looking at alternatives</li><li>Literature survey to find any other models which have emerged in the area of difference generation - None found in the domain of text generation</li><li>Global alignment strategy evaluation with a DP solution - Implemented a DP solution for the alignment and tested the model performance. Significant improvement in the extrinsic evaluation</li></ul> | <ul><li>Experiment with word vector based similarity metric</li><li>Perform some intrinsic evaluations for the alignments to analyze the behaviour</li><li>Start drafting the presentation</li><li>Stretch goal: Try out a multi-decoder architecture to learn similarities and differences simultaneously</li></ul>
Ashwin | <ul><li>Performing more analysis on model predictions - how model performs for random video pairs, same anchor but different paired video</li><li>Finish the final presentation and start report</li><li>Get Multi task learning initial results</li></ul> | <ul><li>Finish the report</li></ul>
Madhura | <ul><ul><li>Max path sum to pick the most similar sentences were extracted and the lowest scores are treated as differences and highest as similarities</li><li>ROUGE scores of 50 were achieved for differences and 60 for similairities. Analysis on the data makes the extracted differences quite reasonable</li><li>The data is still skewed to sentences in the beginning</li>  </ul> | <ul><li>To overcome the skewed data, we need to remove the pair from the path itself</li><li>Create the similarity scores with respect to sentence embedding similarities rather than ROUGE scores</li></ul>


