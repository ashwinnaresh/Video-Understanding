
# Video Understanding - Weekly Updates

This document contains the weekly updates on the video understanding project for the MIIS Capstone requirement.

## Work done since the final presentation in May

An initial topic analysis of the videos in the How-To dataset was done using the video transcriptions. The dominant topics of the videos were Health, Yoga, Cooking, Stitching to name a few. 

## 09/05 - 09/12

Member | Upcoming Tasks 
------ | ---------------
Arvind | Get similar dissimilar videos clustered:<ul><li>Analyze topic distribution</li><li>Get similar videos based on empirical threshold</li><li>Reduce the empirical threshold to get dissimilar videos</li></ul>
Ashwin | Get summarization baselines up and running:<ul><li>Setup environment</li><li>OpenNMT baseline for summarizing videos based on transcription</li><li>Stretch goal: Experiment with action features along with text for summarization</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><li>Literature survey</li><li>Implementation of simple techniques like n-gram overlap, LCS</li><li>Stretch goal : DTW</li></ul>

## 09/12 - 09/19

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | Get similar dissimilar videos clustered:<ul><li>Analyze topic distribution - Checked a 50 topic LDA distribution. The topics seem to be well formed but the choice of the number of latent topics is yet to be confirmed.</li><li>Get similar videos based on empirical threshold - Identified yoga as one of the "hot topics". Evaluated DBSCAN, HDBSCAN, K-means and KNN based on intrinsic measures.</li><li>Reduce the empirical threshold to get dissimilar videos - Basic tests based on KNNs. Threshold setting still an open question</li></ul> | <ul><li>Setup extrinsic evaluation of LDA topics</li><li>Setup extrinsic evaluation of the similar and dissimilar clusters</li><li>Tune the clustering, choice of k in kNN and number of topics based ib the extrinsic evaluation</li></ul>
Ashwin | Get summarization baselines up and running:<ul><li>Setup environment - Environment setup on Rocks cluster</li><li>OpenNMT baseline for summarizing a video based on transcription - Model has been trained. It needs to be evaluated with ROUGE.</li><li>Stretch goal: Experiment with action features along with text for summarization - Not started</li></ul> | <ul><li>Evaluate the trained model on ROUGE and content F1 score metrics</li><li>Experiment with action features along with text for summarization</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><li>Literature survey - Surveyed multiple methods for aligning text in documents</li><li>Implementation of simple techniques like n-gram overlap, LCS - Used other techniques like Rogue and Edit Distance from Survey</li><li>Stretch goal : DTW - Might not be relevant for our use case</li></ul> | <ul><li>Currently experimenting with multiple similiarity scores</li><li>Will have to evaluated the techniques on multiple pairs of videos from different domains to choose the most robust method on identifiying differences</li></ul>

## 09/19 - 09/26

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Setup extrinsic evaluation of LDA topics - Primary evaluation based on the kNN for videos (subjective)</li><li>Setup extrinsic evaluation of the similar and dissimilar clusters - Subjective evaluation completed. Extrinsic evaluation will be possible after a few downstream tasks are defined</li><li>Tune the clustering, choice of k in kNN and number of topics based on the extrinsic evaluation - Implemented a re-ranking metric for kNN based on content similarity in the retrieved neighbours</li></ul> | <ul><li>Try content F1 score and other content similarity measures (METEOR/ ROUGE) to get better distinction between similar and dissimilar videos</li><li>Identify main sets of topics to focus on for initial evaluation</li><li>Improve the interpretibility of the different techniques by juxtaposing the results appropriately.</li><li>Stretch goals: <ul><li>Design model for difference generation</li></li></ul>
Ashwin | <li>Evaluate the trained model on ROUGE and content F1 score metrics - Model evaluated on BLEU-4 (30.797), ROUGE-L (50.3) and METEOR (25.21) scores</li><li>Summarization model trained with video action features and text which gave scores of BLEU-4 (37.197), ROUGE-L (55.6) and METEOR (28.71) </li></ul> | <ul><li>Figure out how to compute content F1 score and evaluate model on it</li><li>Visualize the attention of the summarization model</li><li>Design model architecture for difference generation</li><li>Stretch goals: <ul><li>Implement model and train for difference generation (on dummy data atleast)</li><li>Experiment with object and scene features for summarization</li></ul></li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><li> Implemented a time alignment methodology to align transcriptions with respect to a similarity score</li><li>Evaluated techniques on multiple similarity scores</li></ul> | <ul><li>Implement the Viterbi algortihm to align sentences and use a similairy metric in between to decide insertions and deletions</li><li>Create a grah based to structure to better visualize the sentences which are similar for the videos</li></ul>

## 09/26 - 10/03

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Try content F1 score and other content similarity measures (METEOR/ ROUGE) to get better distinction between similar and dissimilar videos - Content F1 score is not in any literature. New metric defined, which is a modification of METEOR. Need more understanding before using it</li><li>Identify main sets of topics to focus on for initial evaluation - Relationships, Yoga, Excercise were the major topics</li><li>Improve the interpretibility of the different techniques by juxtaposing the results appropriately. - Made a simple UI for comparing different ranking mechanisms</li><li>Stretch goals: <ul><li>Design model for difference generation - Siamese network with a probable heirarchical attention mechanism. Evaluating NMTPytorch for building the seq2seq model.</li></li></ul> | <ul><li>Implement the initial model in NMTPy</li><li>Train the above model on Yoga videos</li><li>Stretch goals: <ul><li>Try MMR based dissimilar sentence retrieval.<li>Perform error analysis on the summaries generated</li></li></li></ul>
Ashwin | <ul><li>Implement model and train for difference generation (on dummy data atleast) - Model has been implemented; it is a siamese seq2seq model with 3-way tied encoders and 2 decoders. The end to end network optimizes the cross entropy loss and there is an auxiliary triplet loss at the encoder.  Gradients explode for some of the training batches randomly leading to NaN loss values; Working on fixing this issue</li><li>Experiment with object and scene features for summarization - Script to extract the object and place features (imagenet and places CNN) is ready and tested on a small sample. There is a storage constraint on the cluster to save these features. This experiment is on hold until the storage logistics are figured out.</li><li>Stretch goal - Manually evaluated some initial data triplets based on the topic similarity</li></ul> | <ul><li>Fix the NaN loss issue</li><li>Train and evaluate model on the sample triplet data extracted so far</li><li>Stretch goal - Experiment with 2 encoders and 1 decoder by randomizing the target as summary of either of the videos and see if network is learning anything</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><ul><li>Implemented the Viterbi algortihm to align sentences and use a similairy metric in between to decide insertions and deletions</li><li>Currently evaluating the approach and researching on other ways to carry out this task</li></ul> | <ul><li>Create a graph based to structure to better visualize the sentences which are similar for the videos</li></ul>

## 10/03 - 10/10

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Implement the initial model in NMTPy - Simplistic model is ready.</li><li>Train the above model on Yoga videos - Created the necessary triplets for training</li><li>Stretch goals: <ul><li>Try MMR based dissimilar sentence retrieval. - results not promising<li>Perform error analysis on the summaries generated - not started</li></li></li></ul> | <ul><li>Add attention to the summary generation</li><li>Evaluate the summaries generated manually</li>
Ashwin | <ul><li>Implement model and train for difference generation (on dummy data atleast) - Model has been implemented; it is a siamese seq2seq model with 3-way tied encoders and 2 decoders. The end to end network optimizes the cross entropy loss and there is an auxiliary triplet loss at the encoder.  Gradients explode for some of the training batches randomly leading to NaN loss values; Working on fixing this issue</li><li>Experiment with object and scene features for summarization - Script to extract the object and place features (imagenet and places CNN) is ready and tested on a small sample. There is a storage constraint on the cluster to save these features. This experiment is on hold until the storage logistics are figured out.</li><li>Stretch goal - Manually evaluated some initial data triplets based on the topic similarity</li></ul> | <ul><li>Fix the NaN loss issue</li><li>Train and evaluate model on the sample triplet data extracted so far</li><li>Stretch goal - Experiment with 2 encoders and 1 decoder by randomizing the target as summary of either of the videos and see if network is learning anything</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><ul><li>Researched on multiple methods to get the right alignment. Taking a different approavh towards the problem</li><li>Going through the dataset to choose pairs of similar videos where the differences are clear</li></ul> | <ul><li>Implement and evaluate the multiple methods researched in the previous week</li><li>Finalize of aligning method and run for rest of the corpus</li></ul>
  
## 10/10 - 10/17

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Add attention to the summary generation - Implemented 2 encoder 1 decoder model with hierarchical attention</li><li>Evaluate the summaries generated manually - proved challenging as the trained model overfit on the data as number of samples were just 1000</li> | <ul><li>Presentation preparation</li><li>Experiment with the entire dataset. <ul><li>Hierarchical attention with similar videos</li><li>Hierarchical attention with dissimilar videos</li><li>Reduce the constraints on triplet creation by sampling from a range of nearest neighbours</li></ul></li><li>Strecth goals: <ul><li>3 encoder 2 decoder model with hierarchical attention implementation</li></ul></li></ul>
Ashwin | <ul><li>Fix the NaN loss issue - loss issue fixed</li><li>Train and evaluate model on the sample triplet data extracted so far - Model seems to be overfitting on the sample data. This conclusion was drawn after manually going through a random sample of model output - Evaluation metrics on held out set: BLEU (27.312), METEOR (24.473) and ROUGE-L (47.1)</li><li>Stretch goal - Experiment with 2 encoders and 1 decoder by randomizing the target as summary of either of the videos and see if network is learning anything - Model seems to be overfitting as it is being trained on just 1K pairs. Evaluation metrics on held out set: BLEU (28.221), METEOR (22.707) and ROUGE-L (46.3)</li></ul> | <ul><li>Experiment with the 2 encoder 1 decoder setup by training on pairs created from the full dataset and see if the summaries generated are comparable to the summarization baselines</li><li>Prepare the slide deck for the mid presentation</li><li>Stretch goal - Experiment using 2 different encoders and weight tied encoders, hierarchical attention and concatenated attention between the 2 encoders</li></ul>
Madhura | Time alignment of transcriptions of video pairs:<ul><ul><li>Finalized on using Rogue as a metric to align the videos</li><li>Created scripts to find differences in videos</li></ul> | <ul><li>Revisit the triplet sampling technique</li><li>Help my teammates with bringing up the baseline</li></ul>

## 10/24 - 10/31

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Presentation preparation - completed mid sem presentation</li><li>Experiment with the entire dataset. - ROUGE scores were not satisfactory. Found a major bug in the hierarchical attention implementation<ul><li>Hierarchical attention with similar videos</li><li>Hierarchical attention with dissimilar videos</li><li>Reduce the constraints on triplet creation by sampling from a range of nearest neighbours</li></ul></li><li>Strecth goals: <ul><li>3 encoder 2 decoder model with hierarchical attention implementation - Finding the bug didn't leave time for this</li></ul></li></ul> | <ul><li>Look at the problem as a sequence tagging problem</li><li>Build a multi-task multi-encoder single decoder network</li><li>Rerun experiments with the new network after the bug fix</li></ul>
Ashwin | <ul><li>Presentation preparation - completed mid sem presentation</li><li>Experiment with the 2 encoder 1 decoder setup by training on pairs created from the full dataset and see if the summaries generated are comparable to the summarization baselines - The 2 encoder 1 decoder setup achieved a ROUGE of 31 whereas the single video summarization baseline achieves a ROUGE of 50.3 <li> Experiment using 2 different encoders and weight tied encoders, hierarchical attention and concatenated attention between the 2 encoders - <ul><li>2 different encoders + 1 decoder - This setup was used for generating differences and the model did not seem to be learning anything</li><li>2 shared encoders + 1 decoder - This setup was used for both generating summaries and differences - It gave a ROUGE of 31 for summaries and 20.8 for differences</li><li>All experiments above were run with hierarchical attention as the model was not learning anything with concatenated attention</li><li>Similar set of experiments were also run for within topic, 2 video summarization and difference generation using the 2 encoder 1 decoder setup - summary generation within topic achieved a ROUGE score of 45.57 whereas on similarity generation (inverse logic for creating differences), model gave a ROUGE of 59.86</li></ul></li><li>Inference from the experiments above - <ul><li>Better sampling of nearest neighbors for input pairs required - directly use Jaccard similarity/ROUGE</li></ul></li></ul> | <ul><li>Look at the problem as sequence tagging problem where each token is tagged as similar/different</li><li>Literature survey on gradient reversal training for multi task learning</li><li>Refine the architecture for the multi-task learning</li><li>Rerun experiments with the new input pairs (based only on jacquard and not topic vectors)</li></ul>
Madhura | Training Dataset Creation and Experiments<ul><ul><li>Created multiple variations for training dataset</li><li>Devised a sampling strategy for choosing similar videos using Rogue, Jaccard and KNN </li><li>Training and implementing variations of the baseline to get differences and similarities between videos</li>  </ul> | <ul><li>Working on changing the problem from a generation problem to a tagging problem</li><li>Run experiments all the various datasets using the tagging methodology</li></ul>

## 10/31 - 11/07

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Look at the problem as a sequence tagging problem - output of the model will now be a multitask output where one of the outputs is the auto-encoded word while the other is the similar/ difference tag</li><li>Build a multi-task multi-encoder single decoder network - Network built</li><li>Rerun experiments with the new network after the bug fix - Awaiting results</li></ul> | <ul><li>Modify NMTPyTorch framework to handle multitask learning system</li><li>Add evaluation for multitask output in the framework</li><li>Run experiments for the implemented multitask system</li></ul>
Ashwin | <ul><li>Look at the problem as sequence tagging problem where each token is tagged as similar/different - Ongoing (data ready, model and evaluation pipeline is being built)</li><li>Literature survey on gradient reversal training for multi task learning - Went through paper on adversarial multitask training which shows that gradient reversal at the task independent layers improves the learning </li><li>Rerun experiments with the new input pairs (based only on jaccard and not topic vectors) - Model is still being trained</li><li>Rerun experiments after fixing decoder bug - Test set ROUGE increases by 1 point.</li></ul> | <ul><li>Multi task learning evaluation pipeline setup</li><li>Evaluate the model on the new input pairs (based on Jaccard)</li></ul>
Madhura | Training Dataset Creation and Experiments<ul><ul><li>Created the dataset to work for the tagging problem.</li><li> Explored the framework to start working on an evaluation pipeline for our multi-task learning implementation</li><li>Training and implementing variations of the baseline to get differences and similarities between videos with the new implementation without the decoder bug</li>  </ul> | <ul><li>We want to achieve some preliminary results regarding the new problem setting</li><li>Experiments needs to be ran on multiple sampling settings as mentioned before</li></ul>
  
## 11/07 - 11/14

Member | Status | Upcoming Tasks
------ | ------- | ----------------
Arvind | <ul><li>Modify NMTPyTorch framework to handle multitask learning system - work in progress. NMTPyTorch isn't as flexible to changes as we had hoped.</li><li>Add evaluation for multitask output in the framework - Seeing if this can be done outside the framework</li><li>Run experiments for the implemented multitask system - Toy experiments have been run. Have to run for the full data</li></ul> | <ul><li>Complete the pending tasks from last week</li><li>Try generating and tagging 1 similar and 1 dissimilar sentence as opposed to a description and compare with the baseline</li><li>Think of a good presentation technique for manual analysis</li></ul>
Ashwin | <ul><li>Evaluate the model on the new input pairs (based on Jaccard) - Model performed worse (ROUGE dropped to 20.4) in generating the summaries as the neighbors sampled using only Jaccard are noisier than our initial neighbors based on topic vectors</li><li>Multi task learning evaluation pipeline setup - Discovered some inconsistencies during initial runs, working on resolving the bugs</li></ul> | <ul><li>Use the video titles to generate similarities and differences and train the model on this</li><li>Manually analyse reasonable similarity/differences between videos in the cooking topic</li></ul>
Madhura | Training Dataset Creation and Experiments<ul><ul><li>Created the dataset to work for the tagging problem.</li><li> Explored the framework to start working on an evaluation pipeline for our multi-task learning implementation</li><li>Training and implementing variations of the baseline to get differences and similarities between videos with the new implementation without the decoder bug</li>  </ul> | <ul><li>We want to achieve some preliminary results regarding the new problem setting</li><li>Experiments needs to be ran on multiple sampling settings as mentioned before</li></ul>


